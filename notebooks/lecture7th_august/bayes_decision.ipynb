{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian Decision Theory\n",
    "\n",
    "- Helps us in identifying tradeoff between various pattern  classification using probability and associated cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Scenario. \n",
    "- Let say you work are hired in a quality control depertment of a company.\n",
    "- Your job(action) is   accept ($a_1$) or reject($a_2$) a product based on some measureable features $\\mathbf{x} = [\\text{length, width, weight, color}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before starting on the job\n",
    "\n",
    "- You start with historical record of accepted and rejected product.\n",
    "- You estimate a priori or prior probability of a product being accepted $P(a_1)$ or $P(a_2)$ rejected, which can be fraction of accepted and rejected product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Decision rule if we only have $P(a_1), P(a_2)$ from historical data\n",
    "\n",
    "<font color=\"red\" > prior information and cost of mis-classification is same </font>\n",
    "\n",
    "i.e decide $a_1$ if $P(a_1) \\gt P(a_2)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can you comment on this rule ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We will end up classifying new product either accept or reject(it look ok under given conditions)\n",
    "- What if prior are equal $P(a_1) == P(a_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Let say we observe a new product with feature $\\mathbf{x}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Given historical data can we do better?\n",
    "\n",
    "- Can we estimate $P(a_1|\\mathbf{x})$ and $P(a_2|\\mathbf{x})$ and have better decision rule?\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "posterior probability $P(a_i|\\mathbf{x})$ given observable feature $\\mathbf{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center ><h1> Yes we know bayes rule </h1></center>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<center>\n",
    "$P(a_1|\\mathbf{x}) = \\frac{P(a_1, \\mathbf{x})}{P(\\mathbf{x})} =\\frac{P(a_1, \\mathbf{x})}{\\sum_{a= a_1, a_2}P(a,\\mathbf{x})}=  \\frac{P(\\mathbf{x}|a_1) P(a_1)}{P(\\mathbf{x})} =\\frac{P(\\mathbf{x}|a_1)P(a_1)}{\\sum_{i= 1}^{2}P(\\mathbf{x}|a_i) P(a_i)} $\n",
    "    </center>\n",
    "    \n",
    "<center> likelihood $P(\\mathbf{x}|a_i)$ and prior $P(a_i)$ control posterior $P(a_i|\\mathbf{x})$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><h1>\n",
    "And how to make the decision\n",
    "    </center>\n",
    "    <br> </h1>\n",
    "<center>\n",
    "use posterior to decide correct class (state of nature)\n",
    "    $ a = \\arg \\max_{a_i} P(a_i|\\mathbf{x})$\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Probability of error\n",
    "\n",
    "$P(error|\\mathbf{x}) = \\begin{cases}\n",
    "      P(a_1|\\mathbf{x}), & \\text{if we choose}\\; a_2 \\\\\n",
    "      P(a_2|\\mathbf{x}), & \\text{if we choose}\\; a_1\n",
    "    \\end{cases} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Bayes decision rule combines prior and likelihood(under same loss)\n",
    "We can minimize the probability of error by using a decision based on  posterior\n",
    "\n",
    "- choose $a_1$ if $P(a_1|\\mathbf{x}) \\gt P(a_2|\\mathbf{x})$ which is same as\n",
    "- choose $a_1$ if $P(\\mathbf{x}|a_1) P(a_1) \\gt P(\\mathbf{x}|a_2) P(a_2)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's talk in a more general setting and more generic cost or loss function\n",
    "- We have $k$ possible classes $\\{y_1, y_2, \\cdots , y_k \\}$, also called states of nature.\n",
    "- And action we can take $\\{a_1, a_2, \\cdots, a_N \\}$\n",
    "- $L(y_i, a_j)$ is loss incured taking action $a_j$ when state of nature is $y_i$. A measure of compatibility between nature state $c_i$ and action taken $a_j$\n",
    "    + like miss classification loss/0-1 loss  $L(y_i, a_j) = \\mathbb{I}(y_i \\ne a_j)$ or squared $(y_i -a_j)^2$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " Let's say having observed $\\mathbf{x}$ we take action $a_j$\n",
    " Then the **risk function or posterior expected loss or conditional risk** is\n",
    " \n",
    " $R(a_j|\\mathbf{x}) =  \\mathbb{E}_{p(y|\\mathbf{x})}[L(y, a)] =\\sum_{i=1}^{k} L(y_i, a_j) P(y_i|\\mathbf{x})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### What action we should take after observing $\\mathbf{x}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>Clearly which minimized the risk or mathematically\n",
    "<br> <br>\n",
    "optimal action/decision procedure/ policy  is = $arg \\min _{a_j} R(a_j|\\mathbf{x})$\n",
    "<br> <br>\n",
    "Hence the **Bayes estimator, also called the Bayes decision rule or minimum risk classifier**, is given\n",
    "by <br> <br>\n",
    " <font size = 6>\n",
    "$arg \\min_a \\mathbb{E}_{p(y|\\mathbf{x})}L(y ,a)$ </font> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's build some Bayes estimators for common loss functions in machine learning\n",
    "\n",
    "## MAP estimate minimizes 0-1 loss(most commonly used in classification problem)\n",
    "\n",
    "$L(y_i, a_j) = \\mathbb{I}(y_i \\ne a_j) = \\begin{cases}\n",
    "      0, & \\text{if }\\; y_i = a_j \\\\\n",
    "      1, & \\text{if}\\; y_i \\ne a_j\n",
    "    \\end{cases} \n",
    "    $\n",
    "    \n",
    "    \n",
    "$y_i \\text{ is true label and } a_i = \\hat{y}_j $ is an estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "$R(a_j|\\mathbf{x}) = \\sum_{i =1}^{i = k}L(y_i, a_j) P(y_i|\\mathbf{x})= \\sum_{i \\ne j} P(y_i|\\mathbf{x})  = 1- P(y_j|\\mathbf{x})$\n",
    "\n",
    "\n",
    "\n",
    "As per bayes decision rule choose choose action which minimized the risk\n",
    "\n",
    "or miximized posterior(mode of posterior) or MAP estimate or $arg \\max_{y} P(y|\\mathbf{x})$\n",
    "\n",
    "See how nicely bayes decision rule justifies our action of choosing maximum posterior probability class under equal loss of miss classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The false positive vs false negative tradeoff\n",
    "Let's focus on binary classification like accept/reject, success/failure etc. \n",
    "- Two type of error we can make\n",
    "    + FP(false positive) i.e $a = \\hat{y} = 1$ when truth is $y =0$\n",
    "    + FN (false negative) i.e $a = \\hat{y} = 0$ when truth is $y =1$\n",
    "0-1 loss consider these two kind of error same but let use more generic loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "td {\n",
       "  font-size: 40px\n",
       "}\n",
       "th {\n",
       "  font-size: 40px\n",
       "}\n",
       "    \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<style>\n",
    "td {\n",
    "  font-size: 40px\n",
    "}\n",
    "th {\n",
    "  font-size: 40px\n",
    "}\n",
    "    \n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>$\\hat{y}=1$</th>\n",
    "    <th>$\\hat{y}=0$</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>y=1</td>\n",
    "    <td>0</td>\n",
    "    <td>$L_{FN}$</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>y=0</td>\n",
    "    <td>$L_{FP}$</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "</table>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Expected loss/risk for two action is \n",
    "- $R(\\hat{y} =0|\\mathbf{x})$ = $L_{FN}P(y=1|\\mathbf{x}$\n",
    "\n",
    "- $R(\\hat{y} =1|\\mathbf{x})$ = $L_{FP}P(y=0|\\mathbf{x})$\n",
    "\n",
    "Choose class $\\hat{y} =1$ if\n",
    "\n",
    "$R(\\hat{y} =0|\\mathbf{x})$ > $R(\\hat{y} =1|\\mathbf{x})$\n",
    "\n",
    "$\\frac{P(y=1|\\mathbf{x}}{P(y=0|\\mathbf{x}} \\gt \\frac{L_{FP}}{L_{FN}} = \\tau$\n",
    "\n",
    "If $L_{FP} = c L_{FN}$ then we will pick $\\hat{y} = 1$ iff $P(y=1|\\mathbf{x} > \\tau$ where $\\tau = \\frac{c}{(1+c)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ROC(receiver operating characteristic) curve and AUC(Area under the curve)\n",
    "\n",
    "<center><font size =6 color = \"green\">ROC curve = plot of (TPR and FPR) </font> </center>\n",
    "\n",
    "Previously choice $\\hat{y}$\n",
    "depends on $\\tau$. We can do better and analyize FP and FN for without comiting to a particular threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "- Let's say we have training data $\\mathcal{D} = {\\mathbf{x_i}, y_i}$ and build our machine learning model $P(y|\\mathbf{x})$ for binary classification $y_i \\in \\{0, 1\\}$.\n",
    "- As we talked previously and shown in the coding HW, we can massage $P(y|\\mathbf{x})$ using monotonic functions to get a economical disriminant function $f(\\mathbf{x})$\n",
    "- $f(\\mathbf{x})$ measure our confidence score for $\\hat{y} =1$\n",
    "- Our decision rule is, $y_i = \\mathbb{I}(f(\\mathbf{x}) > \\tau)$ for some threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For each value of $\\tau$ we get following table(**Confusion matrix**) measuring our error in term of numer of true positive(TP), false positive(FP), true negative(TN) and false negative(FN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>$y=1$</th>\n",
    "    <th>$y=0$</th>\n",
    "    <th></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$\\hat{y}$=1</td>\n",
    "    <td>TP</td>\n",
    "    <td>FP</td>\n",
    "    <td>$\\hat{N}_{+}$ = TP + FN</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$\\hat{y}$=0</td>\n",
    "    <td>FN</td>\n",
    "    <td>TN</td>\n",
    "    <td>$\\hat{N}_{-}$ = TN + FN</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>$N_{+}$ = TP + FN</td>\n",
    "    <td>$N_{-}$ = TN + FP</td>\n",
    "    <td>N= TP+FN +TN+FP</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "True positive rate(**TPR**) = $\\frac{TP}{N_+} \\approx p(\\hat{y} =1| y =1)$\n",
    "\n",
    "false positive rate (**FPR**)(type I error rate) = $\\frac{FP}{N_{-}} \\approx p(\\hat{y} =1| y =0)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Estimate of $P(\\hat{y}|y)$ from confusion matrix\n",
    "<table>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>$y=1$</td>\n",
    "    <td>$y=0$</td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$\\hat{y}$=1</td>\n",
    "    <td>TPR=$\\frac{TP}{N_+}$=sensitive=recall</td>\n",
    "    <td>FPR=$\\frac{FP}{N_{-}}$=type-1 error</td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$\\hat{y}$=0</td>\n",
    "    <td>FNR=$\\frac{FN}{N_+}$=type-II error</td>\n",
    "    <td>TNR=$\\frac{TN}{N_{-}}$=specificity</td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <font size=5 color = \"Maroon\">Calculate TPR and FPR for set of thresholds $\\tau_i$ nd plot them = ROC</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<img height=800 width=800 src=\"fig5_15a.jpg\" alt=\"Smiley face\" >\n",
    "\n",
    "credit: image  from Kevin Muphy book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can also used Area Under the Receiver Operating Characteristic curve to compare two classifer(like A, B in previous picture)\n",
    "- AUC = Area Under the Curve.\n",
    "- AUROC = Area Under the Receiver Operating Characteristic curve\n",
    "\n",
    "AUC is used most of the time to mean AUROC, which is kind of a bad practice but widely used\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For plotting  roc in python see\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
